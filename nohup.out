This is not an error. If you want to use low precision, i.e., fp16, please install the apex with cuda support (https://github.com/NVIDIA/apex) and update pytorch to 1.0
[Resize(size=(384, 192), interpolation=PIL.Image.BICUBIC), RandomHorizontalFlip(p=0.5), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]
4.0211265087127686
Loaded pretrained weights for efficientnet-b0
PCB_Effi(
  (model): EfficientNet(
    (_conv_stem): Conv2dStaticSamePadding(
      3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False
      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)
    )
    (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
    (_blocks): ModuleList(
      (0): MBConvBlock(
        (_depthwise_conv): Conv2dStaticSamePadding(
          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False
          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        )
        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_se_reduce): Conv2dStaticSamePadding(
          32, 8, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_se_expand): Conv2dStaticSamePadding(
          8, 32, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_project_conv): Conv2dStaticSamePadding(
          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_swish): MemoryEfficientSwish()
      )
      (1): MBConvBlock(
        (_expand_conv): Conv2dStaticSamePadding(
          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_depthwise_conv): Conv2dStaticSamePadding(
          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False
          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)
        )
        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_se_reduce): Conv2dStaticSamePadding(
          96, 4, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_se_expand): Conv2dStaticSamePadding(
          4, 96, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_project_conv): Conv2dStaticSamePadding(
          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_swish): MemoryEfficientSwish()
      )
      (2): MBConvBlock(
        (_expand_conv): Conv2dStaticSamePadding(
          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_depthwise_conv): Conv2dStaticSamePadding(
          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False
          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        )
        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_se_reduce): Conv2dStaticSamePadding(
          144, 6, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_se_expand): Conv2dStaticSamePadding(
          6, 144, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_project_conv): Conv2dStaticSamePadding(
          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_swish): MemoryEfficientSwish()
      )
      (3): MBConvBlock(
        (_expand_conv): Conv2dStaticSamePadding(
          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_depthwise_conv): Conv2dStaticSamePadding(
          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False
          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)
        )
        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_se_reduce): Conv2dStaticSamePadding(
          144, 6, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_se_expand): Conv2dStaticSamePadding(
          6, 144, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_project_conv): Conv2dStaticSamePadding(
          144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_swish): MemoryEfficientSwish()
      )
      (4): MBConvBlock(
        (_expand_conv): Conv2dStaticSamePadding(
          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_depthwise_conv): Conv2dStaticSamePadding(
          240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False
          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
        )
        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_se_reduce): Conv2dStaticSamePadding(
          240, 10, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_se_expand): Conv2dStaticSamePadding(
          10, 240, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_project_conv): Conv2dStaticSamePadding(
          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_swish): MemoryEfficientSwish()
      )
      (5): MBConvBlock(
        (_expand_conv): Conv2dStaticSamePadding(
          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_depthwise_conv): Conv2dStaticSamePadding(
          240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False
          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)
        )
        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_se_reduce): Conv2dStaticSamePadding(
          240, 10, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_se_expand): Conv2dStaticSamePadding(
          10, 240, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_project_conv): Conv2dStaticSamePadding(
          240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_swish): MemoryEfficientSwish()
      )
      (6): MBConvBlock(
        (_expand_conv): Conv2dStaticSamePadding(
          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_depthwise_conv): Conv2dStaticSamePadding(
          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False
          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        )
        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_se_reduce): Conv2dStaticSamePadding(
          480, 20, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_se_expand): Conv2dStaticSamePadding(
          20, 480, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_project_conv): Conv2dStaticSamePadding(
          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_swish): MemoryEfficientSwish()
      )
      (7): MBConvBlock(
        (_expand_conv): Conv2dStaticSamePadding(
          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_depthwise_conv): Conv2dStaticSamePadding(
          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False
          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        )
        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_se_reduce): Conv2dStaticSamePadding(
          480, 20, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_se_expand): Conv2dStaticSamePadding(
          20, 480, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_project_conv): Conv2dStaticSamePadding(
          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_swish): MemoryEfficientSwish()
      )
      (8): MBConvBlock(
        (_expand_conv): Conv2dStaticSamePadding(
          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_depthwise_conv): Conv2dStaticSamePadding(
          480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False
          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
        )
        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_se_reduce): Conv2dStaticSamePadding(
          480, 20, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_se_expand): Conv2dStaticSamePadding(
          20, 480, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_project_conv): Conv2dStaticSamePadding(
          480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_swish): MemoryEfficientSwish()
      )
      (9): MBConvBlock(
        (_expand_conv): Conv2dStaticSamePadding(
          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_depthwise_conv): Conv2dStaticSamePadding(
          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False
          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
        )
        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_se_reduce): Conv2dStaticSamePadding(
          672, 28, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_se_expand): Conv2dStaticSamePadding(
          28, 672, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_project_conv): Conv2dStaticSamePadding(
          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_swish): MemoryEfficientSwish()
      )
      (10): MBConvBlock(
        (_expand_conv): Conv2dStaticSamePadding(
          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_depthwise_conv): Conv2dStaticSamePadding(
          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False
          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
        )
        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_se_reduce): Conv2dStaticSamePadding(
          672, 28, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_se_expand): Conv2dStaticSamePadding(
          28, 672, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_project_conv): Conv2dStaticSamePadding(
          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_swish): MemoryEfficientSwish()
      )
      (11): MBConvBlock(
        (_expand_conv): Conv2dStaticSamePadding(
          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_depthwise_conv): Conv2dStaticSamePadding(
          672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False
          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)
        )
        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_se_reduce): Conv2dStaticSamePadding(
          672, 28, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_se_expand): Conv2dStaticSamePadding(
          28, 672, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_project_conv): Conv2dStaticSamePadding(
          672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_swish): MemoryEfficientSwish()
      )
      (12): MBConvBlock(
        (_expand_conv): Conv2dStaticSamePadding(
          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_depthwise_conv): Conv2dStaticSamePadding(
          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False
          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
        )
        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_se_reduce): Conv2dStaticSamePadding(
          1152, 48, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_se_expand): Conv2dStaticSamePadding(
          48, 1152, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_project_conv): Conv2dStaticSamePadding(
          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_swish): MemoryEfficientSwish()
      )
      (13): MBConvBlock(
        (_expand_conv): Conv2dStaticSamePadding(
          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_depthwise_conv): Conv2dStaticSamePadding(
          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False
          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
        )
        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_se_reduce): Conv2dStaticSamePadding(
          1152, 48, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_se_expand): Conv2dStaticSamePadding(
          48, 1152, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_project_conv): Conv2dStaticSamePadding(
          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_swish): MemoryEfficientSwish()
      )
      (14): MBConvBlock(
        (_expand_conv): Conv2dStaticSamePadding(
          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_depthwise_conv): Conv2dStaticSamePadding(
          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False
          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)
        )
        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_se_reduce): Conv2dStaticSamePadding(
          1152, 48, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_se_expand): Conv2dStaticSamePadding(
          48, 1152, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_project_conv): Conv2dStaticSamePadding(
          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_swish): MemoryEfficientSwish()
      )
      (15): MBConvBlock(
        (_expand_conv): Conv2dStaticSamePadding(
          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_depthwise_conv): Conv2dStaticSamePadding(
          1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False
          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)
        )
        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_se_reduce): Conv2dStaticSamePadding(
          1152, 48, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_se_expand): Conv2dStaticSamePadding(
          48, 1152, kernel_size=(1, 1), stride=(1, 1)
          (static_padding): Identity()
        )
        (_project_conv): Conv2dStaticSamePadding(
          1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False
          (static_padding): Identity()
        )
        (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
        (_swish): MemoryEfficientSwish()
      )
    )
    (_conv_head): Conv2dStaticSamePadding(
      320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False
      (static_padding): Identity()
    )
    (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)
    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)
    (_dropout): Dropout(p=0.2, inplace=False)
    (_fc): Linear(in_features=1280, out_features=1000, bias=True)
    (_swish): MemoryEfficientSwish()
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(4, 1))
  (dropout): Dropout(p=0.5, inplace=False)
  (classifierA0): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1280, out_features=256, bias=True)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Dropout(p=0.5, inplace=False)
    )
    (classifier): Sequential(
      (0): Linear(in_features=256, out_features=751, bias=True)
    )
  )
  (classifierA1): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1280, out_features=256, bias=True)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Dropout(p=0.5, inplace=False)
    )
    (classifier): Sequential(
      (0): Linear(in_features=256, out_features=751, bias=True)
    )
  )
  (classifierA2): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1280, out_features=256, bias=True)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Dropout(p=0.5, inplace=False)
    )
    (classifier): Sequential(
      (0): Linear(in_features=256, out_features=751, bias=True)
    )
  )
  (classifierA3): ClassBlock(
    (add_block): Sequential(
      (0): Linear(in_features=1280, out_features=256, bias=True)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Dropout(p=0.5, inplace=False)
    )
    (classifier): Sequential(
      (0): Linear(in_features=256, out_features=751, bias=True)
    )
  )
)
Epoch 1/60
----------
train Loss: 20.6091 Acc: 0.1800
val Loss: 15.5498 Acc: 0.3262
Training complete in 0m 59s

Epoch 2/60
----------
train Loss: 11.0996 Acc: 0.5696
val Loss: 9.6146 Acc: 0.5739
Training complete in 1m 54s

Epoch 3/60
----------
train Loss: 7.1407 Acc: 0.7572
val Loss: 6.9895 Acc: 0.6818
Training complete in 2m 49s

Epoch 4/60
----------
train Loss: 4.9447 Acc: 0.8585
val Loss: 4.9713 Acc: 0.7883
Training complete in 3m 44s

Epoch 5/60
----------
train Loss: 3.6861 Acc: 0.9102
val Loss: 4.1880 Acc: 0.8282
Training complete in 4m 39s

Epoch 6/60
----------
train Loss: 2.9246 Acc: 0.9381
val Loss: 4.6820 Acc: 0.8029
Training complete in 5m 34s

Epoch 7/60
----------
train Loss: 2.2918 Acc: 0.9597
val Loss: 3.0452 Acc: 0.8655
Training complete in 6m 29s

Epoch 8/60
----------
train Loss: 1.9630 Acc: 0.9654
val Loss: 2.4991 Acc: 0.9041
Training complete in 7m 24s

Epoch 9/60
----------
train Loss: 1.5822 Acc: 0.9783
val Loss: 2.4142 Acc: 0.8961
Training complete in 8m 19s

Epoch 10/60
----------
train Loss: 1.3930 Acc: 0.9812
val Loss: 2.4243 Acc: 0.8988
Training complete in 9m 14s

Epoch 11/60
----------
train Loss: 1.1882 Acc: 0.9874
val Loss: 2.4863 Acc: 0.8948
Training complete in 10m 9s

Epoch 12/60
----------
train Loss: 1.0198 Acc: 0.9910
val Loss: 1.9153 Acc: 0.9188
Training complete in 11m 4s

Epoch 13/60
----------
train Loss: 0.9200 Acc: 0.9919
val Loss: 2.1114 Acc: 0.8988
Training complete in 12m 1s

Epoch 14/60
----------
train Loss: 0.8378 Acc: 0.9929
val Loss: 1.8484 Acc: 0.9161
Training complete in 12m 56s

Epoch 15/60
----------
train Loss: 0.7279 Acc: 0.9955
val Loss: 1.9011 Acc: 0.9121
Training complete in 13m 52s

Epoch 16/60
----------
train Loss: 0.6974 Acc: 0.9946
val Loss: 1.5677 Acc: 0.9348
Training complete in 14m 47s

Epoch 17/60
----------
train Loss: 0.6147 Acc: 0.9952
val Loss: 1.7107 Acc: 0.9241
Training complete in 15m 42s

Epoch 18/60
----------
train Loss: 0.5862 Acc: 0.9959
val Loss: 1.4784 Acc: 0.9348
Training complete in 16m 37s

Epoch 19/60
----------
train Loss: 0.5733 Acc: 0.9952
val Loss: 1.6339 Acc: 0.9281
Training complete in 17m 32s

Epoch 20/60
----------
train Loss: 0.4902 Acc: 0.9967
val Loss: 1.4514 Acc: 0.9241
Training complete in 18m 27s

Epoch 21/60
----------
train Loss: 0.3216 Acc: 0.9977
val Loss: 1.0694 Acc: 0.9427
Training complete in 19m 22s

Epoch 22/60
----------
train Loss: 0.2489 Acc: 0.9979
val Loss: 1.0489 Acc: 0.9427
Training complete in 20m 17s

Epoch 23/60
----------
train Loss: 0.2241 Acc: 0.9978
val Loss: 0.9699 Acc: 0.9467
Training complete in 21m 12s

Epoch 24/60
----------
train Loss: 0.2104 Acc: 0.9979
val Loss: 0.9916 Acc: 0.9427
Training complete in 22m 7s

Epoch 25/60
----------
train Loss: 0.1977 Acc: 0.9979
val Loss: 0.9630 Acc: 0.9414
Training complete in 23m 2s

Epoch 26/60
----------
train Loss: 0.1891 Acc: 0.9979
val Loss: 0.9638 Acc: 0.9441
Training complete in 23m 57s

Epoch 27/60
----------
train Loss: 0.1886 Acc: 0.9978
val Loss: 0.9516 Acc: 0.9441
Training complete in 24m 52s

Epoch 28/60
----------
train Loss: 0.1838 Acc: 0.9979
val Loss: 0.9596 Acc: 0.9467
Training complete in 25m 47s

Epoch 29/60
----------
train Loss: 0.1765 Acc: 0.9979
val Loss: 0.9268 Acc: 0.9454
Training complete in 26m 42s

Epoch 30/60
----------
train Loss: 0.1798 Acc: 0.9978
val Loss: 0.9324 Acc: 0.9441
Training complete in 27m 37s

Epoch 31/60
----------
train Loss: 0.1798 Acc: 0.9979
val Loss: 0.9364 Acc: 0.9441
Training complete in 28m 32s

Epoch 32/60
----------
train Loss: 0.1729 Acc: 0.9979
val Loss: 0.9609 Acc: 0.9441
Training complete in 29m 27s

Epoch 33/60
----------
train Loss: 0.1793 Acc: 0.9979
val Loss: 0.9419 Acc: 0.9441
Training complete in 30m 23s

Epoch 34/60
----------
train Loss: 0.1747 Acc: 0.9979
val Loss: 0.9494 Acc: 0.9454
Training complete in 31m 18s

Epoch 35/60
----------
train Loss: 0.1695 Acc: 0.9979
val Loss: 0.9343 Acc: 0.9441
Training complete in 32m 13s

Epoch 36/60
----------
train Loss: 0.1679 Acc: 0.9979
val Loss: 0.9285 Acc: 0.9467
Training complete in 33m 8s

Epoch 37/60
----------
train Loss: 0.1746 Acc: 0.9979
val Loss: 0.9084 Acc: 0.9454
Training complete in 34m 3s

Epoch 38/60
----------
train Loss: 0.1697 Acc: 0.9979
val Loss: 0.9525 Acc: 0.9414
Training complete in 34m 58s

Epoch 39/60
----------
train Loss: 0.1781 Acc: 0.9978
val Loss: 0.9655 Acc: 0.9414
Training complete in 35m 53s

Epoch 40/60
----------
train Loss: 0.1642 Acc: 0.9979
val Loss: 0.9536 Acc: 0.9414
Training complete in 36m 48s

Epoch 41/60
----------
train Loss: 0.1700 Acc: 0.9979
val Loss: 0.9442 Acc: 0.9414
Training complete in 37m 43s

Epoch 42/60
----------
train Loss: 0.1668 Acc: 0.9979
val Loss: 0.9533 Acc: 0.9414
Training complete in 38m 39s

Epoch 43/60
----------
train Loss: 0.1747 Acc: 0.9979
val Loss: 0.9096 Acc: 0.9427
Training complete in 39m 34s

Epoch 44/60
----------
train Loss: 0.1701 Acc: 0.9979
val Loss: 0.9370 Acc: 0.9441
Training complete in 40m 29s

Epoch 45/60
----------
train Loss: 0.1712 Acc: 0.9979
val Loss: 0.9395 Acc: 0.9427
Training complete in 41m 24s

Epoch 46/60
----------
train Loss: 0.1680 Acc: 0.9979
val Loss: 0.9480 Acc: 0.9427
Training complete in 42m 19s

Epoch 47/60
----------
train Loss: 0.1691 Acc: 0.9979
val Loss: 0.9229 Acc: 0.9441
Training complete in 43m 17s

Epoch 48/60
----------
train Loss: 0.1715 Acc: 0.9979
val Loss: 0.9309 Acc: 0.9427
Training complete in 44m 12s

Epoch 49/60
----------
train Loss: 0.1728 Acc: 0.9979
val Loss: 0.9487 Acc: 0.9427
Training complete in 45m 8s

Epoch 50/60
----------
train Loss: 0.1651 Acc: 0.9979
val Loss: 0.9397 Acc: 0.9441
Training complete in 46m 4s

Epoch 51/60
----------
train Loss: 0.1704 Acc: 0.9979
val Loss: 0.9345 Acc: 0.9441
Training complete in 46m 60s

Epoch 52/60
----------
train Loss: 0.1665 Acc: 0.9979
val Loss: 0.9182 Acc: 0.9441
Training complete in 47m 55s

Epoch 53/60
----------
train Loss: 0.1697 Acc: 0.9978
val Loss: 0.9278 Acc: 0.9441
Training complete in 48m 50s

Epoch 54/60
----------
train Loss: 0.1674 Acc: 0.9979
val Loss: 0.9434 Acc: 0.9427
Training complete in 49m 46s

Epoch 55/60
----------
train Loss: 0.1728 Acc: 0.9977
val Loss: 0.9429 Acc: 0.9427
Training complete in 50m 41s

Epoch 56/60
----------
train Loss: 0.1648 Acc: 0.9979
val Loss: 0.9302 Acc: 0.9427
Training complete in 51m 37s

Epoch 57/60
----------
train Loss: 0.1692 Acc: 0.9979
val Loss: 0.9449 Acc: 0.9427
Training complete in 52m 32s

Epoch 58/60
----------
train Loss: 0.1715 Acc: 0.9979
val Loss: 0.9328 Acc: 0.9427
Training complete in 53m 27s

Epoch 59/60
----------
train Loss: 0.1663 Acc: 0.9979
val Loss: 0.9427 Acc: 0.9427
Training complete in 54m 22s

Epoch 60/60
----------
train Loss: 0.1675 Acc: 0.9979
val Loss: 0.9337 Acc: 0.9427
Training complete in 55m 20s

Training complete in 55m 20s
